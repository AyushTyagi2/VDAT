(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[8698],{2250:(e,a,i)=>{Promise.resolve().then(i.bind(i,1855))},2423:(e,a,i)=>{"use strict";i.d(a,{A:()=>t});let t=(0,i(7401).A)("Calendar",[["path",{d:"M8 2v4",key:"1cmpym"}],["path",{d:"M16 2v4",key:"4m81vk"}],["rect",{width:"18",height:"18",x:"3",y:"4",rx:"2",key:"1hopcy"}],["path",{d:"M3 10h18",key:"8toen8"}]])},738:(e,a,i)=>{"use strict";i.d(a,{A:()=>t});let t=(0,i(7401).A)("EyeOff",[["path",{d:"M10.733 5.076a10.744 10.744 0 0 1 11.205 6.575 1 1 0 0 1 0 .696 10.747 10.747 0 0 1-1.444 2.49",key:"ct8e1f"}],["path",{d:"M14.084 14.158a3 3 0 0 1-4.242-4.242",key:"151rxh"}],["path",{d:"M17.479 17.499a10.75 10.75 0 0 1-15.417-5.151 1 1 0 0 1 0-.696 10.75 10.75 0 0 1 4.446-5.143",key:"13bj9a"}],["path",{d:"m2 2 20 20",key:"1ooewy"}]])},2598:(e,a,i)=>{"use strict";i.d(a,{A:()=>t});let t=(0,i(7401).A)("Eye",[["path",{d:"M2.062 12.348a1 1 0 0 1 0-.696 10.75 10.75 0 0 1 19.876 0 1 1 0 0 1 0 .696 10.75 10.75 0 0 1-19.876 0",key:"1nclc0"}],["circle",{cx:"12",cy:"12",r:"3",key:"1v7zrd"}]])},4081:(e,a,i)=>{"use strict";i.d(a,{A:()=>t});let t=(0,i(7401).A)("FileText",[["path",{d:"M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z",key:"1rqfz7"}],["path",{d:"M14 2v4a2 2 0 0 0 2 2h4",key:"tnqrlb"}],["path",{d:"M10 9H8",key:"b1mrlr"}],["path",{d:"M16 13H8",key:"t4e002"}],["path",{d:"M16 17H8",key:"z1uh3a"}]])},6462:(e,a,i)=>{"use strict";i.d(a,{A:()=>t});let t=(0,i(7401).A)("Mail",[["rect",{width:"20",height:"16",x:"2",y:"4",rx:"2",key:"18n3k1"}],["path",{d:"m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7",key:"1ocrg3"}]])},2104:(e,a,i)=>{"use strict";i.d(a,{A:()=>t});let t=(0,i(7401).A)("Moon",[["path",{d:"M12 3a6 6 0 0 0 9 9 9 9 0 1 1-9-9Z",key:"a7tn18"}]])},7725:(e,a,i)=>{"use strict";i.d(a,{A:()=>t});let t=(0,i(7401).A)("Sun",[["circle",{cx:"12",cy:"12",r:"4",key:"4exip2"}],["path",{d:"M12 2v2",key:"tus03m"}],["path",{d:"M12 20v2",key:"1lh1kg"}],["path",{d:"m4.93 4.93 1.41 1.41",key:"149t6j"}],["path",{d:"m17.66 17.66 1.41 1.41",key:"ptbguv"}],["path",{d:"M2 12h2",key:"1t8f8n"}],["path",{d:"M20 12h2",key:"1q8mjw"}],["path",{d:"m6.34 17.66-1.41 1.41",key:"1m8zz5"}],["path",{d:"m19.07 4.93-1.41 1.41",key:"1shlcs"}]])},1855:(e,a,i)=>{"use strict";i.r(a),i.d(a,{default:()=>j});var t=i(5155),s=i(2115),r=i(4055),n=i(8370),o=i(5087),l=i(9219),d=i(5683),c=i(7725),h=i(2104),m=i(3467),p=i(2423),g=i(6889),u=i(1466),f=i(4081),x=i(1902),b=i(1719),y=i(738),v=i(2598),w=i(6462);let k={hidden:{opacity:0,y:30},visible:{opacity:1,y:0,transition:{duration:.8,ease:"easeOut"}}},N={hidden:{opacity:0},visible:{opacity:1,transition:{staggerChildren:.1,delayChildren:.2}}};function j(e){let{sessionTitle:a="Processor and FPGA",sessionTime:i="11:45 AM - 1:15 PM",sessionDate:j="August 9, 2025",sessionChairperson:A="Chair 1: Mr. H S Jattana , Chair 2:  Prof. Amit Panday",sessionDescription:P="",papers:M=[{id:"288",time:"11:30 AM - 11:45 AM",title:"Low-Power Approximate Multiplier Architecture for Deep Neural Networks",authors:["Pragun Jaswal","  Hemanth Krishna Lavati "," Srinivasu bodapati"],abstract:"This paper proposes an energy-efficient approximate multiplier architecture for deep neural network (DNN) applications. A 4:2 compressor, introducing only a single combination error, is designed and integrated into an 8\xd78 unsigned multiplier. This integration significantly reduces the usage of exact compressors while preserving low error rates. The proposed multiplier is employed within a custom convolution layer and evaluated on neural network tasks, including image recognition and denoising. Hardware evaluation demonstrates that the proposed design achieves up to 30.24% energy savings compared to the best of existing multipliers. In image denoising, the custom approximate convolution layer achieves improved Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Measure (SSIM) compared to other approximate designs. Additionally, when applied to handwritten digit recognition, the model maintains high classification accuracy. These results demonstrate that the proposed architecture offers a favorable balance between energy efficiency and computational precision, making it suitable for low-power AI hardware implementations.",mainContact:{name:"Hemanth Krishna Lavati",email:"hemanth.krishna412@gmail.com"}},{id:"92",time:"11:45 AM - 12:00 PM",title:"High-Performance Data Level Parallelism based Variable Precision 32-bit Co-Processor Design",authors:["Mohamed Asan Basiri M","Joel Israel"],abstract:"A co-processor is a hardware accelerator used to improve the performance of the primary processor. One of the best methods to enhance the co-processor's performance is to take advantage of the idea of parallelism. In this paper, a high performance 32-bit co-processor is proposed. The proposed 32-bit co-processor exploits the idea of data-level parallelism (DLP), where multiple less precision operations such as additions, subtractions, multiplications, divisions, shiftings, and logical operations are performed in parallel. Also, we propose a variable precision 32 bit divider to perform one 32-bit division or tow 16-bit divisions or four 8-bit divisions in parallel. Similarly, we propose a 32-bit variable precision right/left shifter, where one 32-bit shift or two 16-bit shifts or four 8-bit shifts are performed in parallel. These proposed 32-bit variable precision divider and shifters are the part of our proposed 32-bit co-processor. As an application part, the proposed 32-bit co-processor is used in the calculation of the (32\xd732)-point forward 2D integer discrete cosine transform, which is used to compress a (32\xd732)-point greyscale image. The forward 2D integer discrete cosine transform of the image is calculated using our proposed co-processor with hardware software co-design in Xilinx SDK with Zynq 7000 SoC as the target FPGA.",mainContact:{name:"Mohamed Asan Basiri M",email:"asanbasiri@gmail.com"}},{id:"362",time:"12:00 PM - 12:15 PM",title:"Energy Efficient V-Band Low Noise Amplifier with Enhanced Noise Performance for Satellite Communications.",authors:["Namrata Tripathi","Saroj Mondal"],abstract:"This paper presents a V-band low-noise amplifier (LNA) designed using a two-stage cascode architecture in 65 nm CMOS technology. Incorporating source degeneration and noise canceling techniques, the LNA achieves a peak gain of 20.8 dB at 56.8 GHz, with a 3-dB bandwidth ranging from 54 to 60.6 GHz. Operating from a 1.2 V supply, it consumes 7.2 mW of DC power and attains a minimum noise figure (NF) of 4.25 dB. The input 1-dB compression point (IP1dB) is −11.68 dBm at 58 GHz. These performance metrics demonstrate the LNA's suitability for low-power satellite communication applications.",mainContact:{name:"Contact",email:"ee23ms004@iitdh.ac.in"}},{id:"85",time:"12:15 PM - 12:30 PM",title:"HLS based Hardware Watermarking using an Integrated Framework based on Encoded Dependency Matrix and Encrypted Load-Factor Signature",authors:["Anirban Sengupta","Vishal Chourasia"],abstract:"This paper presents a novel secure High-Level Synthesis (HLS) based hardware watermarking methodology for detective countermeasure against intellectual property (IP) piracy and false IP ownership attacks. The proposed HLS based watermarking technique exploits an integrated framework based on encoded dependency matrix and encrypted load-factor signature. The proposed approach can produce more robust and secure IP designs against ghost insertion search attack, false IP ownership and tampering or removal attack as indicated through significantly lower probability of coincidence and higher tamper tolerance values. Comparison of proposed approach with related works indicated superior security at zero design cost overhead",mainContact:{name:"Anirban Sengupta",email:"asengupt@iiti.ac.in"}},{id:"299",time:"12:30 PM - 12:45 PM",title:"Hardware Implementation of True Motion Prediction for WebP Lossy Image Compression",authors:["Anurag Sharma","Srinivasu Bodapati"],abstract:"With the rapid growth of visual data in multimedia and embedded systems, there is a pressing need for lightweight and efficient image compression for IoT applications. This work presents a hardware architecture for the True Motion Prediction (TM_PRED) utilized in the WebP lossy image compression, which is a key contributor to spatial redundancy removal. The proposed architecture, synthesized on FPGA, utilizes 310 LUTs, 221 flip-flops, a BRAM, and achieves a maximum operating frequency of 253 MHz. The predicted pixel values are further utilized in a software-based WebP encoder to evaluate end-to-end compression performance. The proposed architecture is validated using grayscale images from the IEEE C4L dataset, and the results reveal that the TM_PRED achieves 6%–11% improvement in PSNR, 3%–12% improvement in SSIM, and 33%–58% reduction in file size compared to JPEG across varying quality levels. The results demonstrate that offloading the intra prediction module to hardware can significantly enhance compression efficiency while remaining suitable for real-time image applications.",mainContact:{name:"Contact",email:"s23079@students.iitmandi.ac.in"}},{id:"335",time:"12:45 PM - 1:00 PM",title:"Edge-AI based Real-Time Infant Monitoring using Multimodal Sensing",authors:["Hrushikesh Ramilla","Ravindranadh Ambica Golakoti","Pradyut Kumar Sanki","Biswabandhu Jana"],abstract:"Abstract—Continuous parental supervision is particularly challenging during an infant's sleep, a period when many un- expected risks can arise. To enhance infant safety, we developed a lightweight, edge-AI based real-time infant monitoring system. The proposed system integrates both audio and visual surveil- lance to detect potential risks during sleep. For audio monitoring, we developed a deep learning model combining Convolutional Neural Networks (CNN), Bidirectional Long Short-Term Memory (BiLSTM), and an attention mechanism to differentiate between real distress cries and normal baby sounds. On the visual front, a camera feeds data into a MediaPipe-based module that assesses key safety parameters, including face visibility, body coverage, and safe sleeping posture. The entire system is implemented on a Raspberry Pi board, ensuring efficient, low-power edge processing. In manual testing, the system has achieved 90% and 94% accuracy for real-time audio and video performance. Overall, the proposed solution offers a practical, cost-effective approach for enhancing infant safety in home environments. Index Terms—Infant monitoring, Real-time systems, Deep learning, Computer vision",mainContact:{name:"Hrushikesh Ramilla",email:"ramillahrushikesh@gmail.com"}}]}=e,[C,T]=(0,s.useState)(!1),[S,E]=(0,s.useState)({}),[I,D]=(0,s.useState)({}),{scrollYProgress:H}=(0,o.L)();(0,s.useEffect)(()=>{window.matchMedia("(prefers-color-scheme: dark)").matches&&T(!0)},[]),(0,s.useEffect)(()=>{document.documentElement.classList.toggle("dark",C)},[C]);let L=e=>{E(a=>({...a,[e]:!a[e]}))},z=e=>{D(a=>({...a,[e]:!a[e]}))};return(0,t.jsxs)("div",{className:"relative bg-gradient-to-br from-slate-50 via-blue-50 to-indigo-50 dark:from-gray-900 dark:via-slate-900 dark:to-indigo-900 transition-colors duration-700 min-h-screen",children:[(0,t.jsx)("header",{children:(0,t.jsx)(n.default,{})}),(0,t.jsxs)("div",{className:"fixed inset-0 overflow-hidden pointer-events-none",children:[(0,t.jsx)("div",{className:"absolute -top-40 -right-40 w-80 h-80 bg-gradient-to-br from-purple-400/20 to-pink-400/20 rounded-full blur-3xl animate-pulse"}),(0,t.jsx)("div",{className:"absolute -bottom-40 -left-40 w-80 h-80 bg-gradient-to-br from-blue-400/20 to-cyan-400/20 rounded-full blur-3xl animate-pulse delay-1000"}),(0,t.jsx)("div",{className:"absolute top-1/2 left-1/2 transform -translate-x-1/2 -translate-y-1/2 w-96 h-96 bg-gradient-to-br from-indigo-400/10 to-purple-400/10 rounded-full blur-3xl animate-pulse delay-2000"})]}),(0,t.jsx)(l.P.div,{className:"fixed top-0 left-0 right-0 h-1 bg-gradient-to-r from-purple-500 via-blue-500 to-cyan-500 origin-left z-50",style:{scaleX:H}}),(0,t.jsx)(l.P.button,{whileHover:{scale:1.1},whileTap:{scale:.9},onClick:()=>T(!C),className:"fixed bottom-6 right-6 p-4 bg-white/80 dark:bg-gray-800/80 backdrop-blur-lg rounded-full shadow-2xl hover:shadow-3xl transition-all duration-300 z-40",children:C?(0,t.jsx)(c.A,{className:"w-6 h-6 text-yellow-400"}):(0,t.jsx)(h.A,{className:"w-6 h-6 text-gray-700"})}),(0,t.jsxs)("header",{className:"relative overflow-hidden mb-12",children:[(0,t.jsx)("div",{className:"absolute inset-0 bg-gradient-to-br from-purple-900/95 via-blue-900/90 to-indigo-900/95 backdrop-blur-sm"}),(0,t.jsx)("div",{className:'\n            absolute inset-0\n            bg-[url("data:image/svg+xml,%3Csvg%20width%3D%2260%22%20height%3D%2260%22%20viewBox%3D%220%200%2060%2060%22%20xmlns%3D%22http://www.w3.org/2000/svg%22%3E%3Cg%20fill%3D%22none%22%20fill-rule%3D%22evenodd%22%3E%3Cg%20fill%3D%22%23ffffff%22%20fill-opacity%3D%220.05%22%3E%3Ccircle%20cx%3D%2230%22%20cy%3D%2230%22%20r%3D%222%22/%3E%3C/g%3E%3C/g%3E%3C/svg%3E")]\n            opacity-50\n          '}),(0,t.jsxs)("div",{className:"relative z-10 px-8 py-16",children:[(0,t.jsx)(l.P.div,{initial:{scale:0,rotate:-180},animate:{scale:1,rotate:0},transition:{duration:1,ease:"easeOut"},className:"inline-block p-4 bg-white/10 backdrop-blur-lg rounded-2xl mb-6",children:(0,t.jsx)(m.A,{className:"w-12 h-12 text-white"})}),(0,t.jsx)(l.P.h1,{initial:{scale:.8,opacity:0},animate:{scale:1,opacity:1},transition:{duration:1,ease:"easeOut"},className:"text-2xl md:text-3xl lg:text-5xl font-black tracking-tight mb-4 text-white leading-tight",children:a}),(0,t.jsx)(l.P.p,{initial:{opacity:0,y:20},animate:{opacity:1,y:0},transition:{delay:.3,duration:.8},className:"text-lg text-white/90 max-w-4xl mb-8 leading-relaxed",children:P}),(0,t.jsxs)(l.P.div,{initial:{opacity:0,y:20},animate:{opacity:1,y:0},transition:{delay:.5,duration:.8},className:"flex flex-wrap gap-4 text-white/90",children:[(0,t.jsxs)("div",{className:"flex items-center gap-2 bg-white/10 backdrop-blur-lg px-4 py-2 rounded-full",children:[(0,t.jsx)(p.A,{className:"w-5 h-5"}),(0,t.jsx)("span",{children:j})]}),(0,t.jsxs)("div",{className:"flex items-center gap-2 bg-white/10 backdrop-blur-lg px-4 py-2 rounded-full",children:[(0,t.jsx)(g.A,{className:"w-5 h-5"}),(0,t.jsx)("span",{children:i})]}),(0,t.jsxs)("div",{className:"flex items-center gap-2 bg-white/10 backdrop-blur-lg px-4 py-2 rounded-full",children:[(0,t.jsx)(u.A,{className:"w-5 h-5"}),(0,t.jsx)("span",{children:A})]}),(0,t.jsxs)("div",{className:"flex items-center gap-2 bg-white/10 backdrop-blur-lg px-4 py-2 rounded-full",children:[(0,t.jsx)(f.A,{className:"w-5 h-5"}),(0,t.jsxs)("span",{children:[M.length," Paper",M.length>1?"s":""]})]})]})]})]}),(0,t.jsx)("main",{className:"max-w-7xl mx-auto px-4 pb-16",children:(0,t.jsxs)(l.P.div,{variants:N,initial:"hidden",animate:"visible",className:"space-y-8",children:[(0,t.jsxs)("div",{className:"text-center mb-12",children:[(0,t.jsx)("h2",{className:"text-4xl font-bold text-gray-900 dark:text-gray-100 mb-4",children:"Research Papers"}),(0,t.jsx)("p",{className:"text-xl text-gray-600 dark:text-gray-400",children:"Explore the cutting-edge research presented in this session"})]}),M.map((e,a)=>(0,t.jsxs)(l.P.div,{variants:k,className:"bg-white/80 dark:bg-gray-800/80 backdrop-blur-lg rounded-3xl shadow-2xl border border-gray-200/50 dark:border-gray-700/50 overflow-hidden hover:shadow-3xl transition-all duration-500",children:[(0,t.jsxs)("div",{className:"bg-gradient-to-r from-indigo-600 to-purple-600 text-white p-6",children:[(0,t.jsxs)("div",{className:"flex justify-between items-start gap-4",children:[(0,t.jsxs)("div",{className:"flex-1",children:[(0,t.jsxs)("div",{className:"flex items-center gap-3 mb-3",children:[(0,t.jsx)("div",{className:"w-8 h-8 bg-white/20 rounded-full flex items-center justify-center text-sm font-bold",children:a+1}),(0,t.jsxs)("span",{className:"text-sm font-medium opacity-90",children:["Paper ID: ",e.id]})]}),(0,t.jsx)("h3",{className:"text-xl md:text-2xl font-bold leading-tight",children:e.title}),(0,t.jsx)("p",{className:"text-sm text-gray-200 mt-1",children:e.time})]}),(0,t.jsx)(l.P.button,{whileHover:{scale:1.05},whileTap:{scale:.95},onClick:()=>L(e.id),className:"p-2 bg-white/10 backdrop-blur-lg rounded-full hover:bg-white/20 transition-all duration-300",children:S[e.id]?(0,t.jsx)(x.A,{className:"w-6 h-6"}):(0,t.jsx)(b.A,{className:"w-6 h-6"})})]}),(0,t.jsx)("div",{className:"mt-4",children:(0,t.jsx)("div",{className:"flex flex-wrap gap-2",children:e.authors.map((e,a)=>(0,t.jsx)("span",{className:"px-3 py-1 bg-white/10 backdrop-blur-lg rounded-full text-sm",children:e},a))})})]}),(0,t.jsx)(d.N,{children:S[e.id]&&(0,t.jsx)(l.P.div,{initial:{height:0,opacity:0},animate:{height:"auto",opacity:1},exit:{height:0,opacity:0},transition:{duration:.5,ease:"easeInOut"},className:"overflow-hidden",children:(0,t.jsxs)("div",{className:"p-6 space-y-6",children:[(0,t.jsxs)("div",{className:"bg-gray-50 dark:bg-gray-700/50 rounded-2xl p-6",children:[(0,t.jsxs)("div",{className:"flex items-center justify-between mb-4",children:[(0,t.jsxs)("h4",{className:"text-xl font-bold text-gray-900 dark:text-gray-100 flex items-center gap-2",children:[(0,t.jsx)(f.A,{className:"w-5 h-5"}),"Abstract"]}),(0,t.jsx)(l.P.button,{whileHover:{scale:1.05},whileTap:{scale:.95},onClick:()=>z(e.id),className:"p-2 bg-white dark:bg-gray-600 rounded-full hover:bg-gray-100 dark:hover:bg-gray-500 transition-all duration-300",children:I[e.id]?(0,t.jsx)(y.A,{className:"w-4 h-4"}):(0,t.jsx)(v.A,{className:"w-4 h-4"})})]}),(0,t.jsx)(l.P.div,{initial:!1,animate:{height:I[e.id]?"auto":"100px"},transition:{duration:.3,ease:"easeInOut"},className:"overflow-hidden",children:(0,t.jsx)("p",{className:"text-gray-700 dark:text-gray-300 leading-relaxed",children:e.abstract})})]}),(0,t.jsxs)("div",{className:"bg-gradient-to-r from-blue-50 to-indigo-50 dark:from-blue-900/20 dark:to-indigo-900/20 rounded-2xl p-6",children:[(0,t.jsxs)("h4",{className:"text-xl font-bold text-gray-900 dark:text-gray-100 mb-4 flex items-center gap-2",children:[(0,t.jsx)(u.A,{className:"w-5 h-5"}),"Main Contact"]}),(0,t.jsx)("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-4",children:(0,t.jsx)("div",{className:"space-y-2",children:(0,t.jsxs)("div",{className:"flex items-center gap-2 text-gray-700 dark:text-gray-300",children:[(0,t.jsx)(w.A,{className:"w-4 h-4 text-indigo-600"}),(0,t.jsx)("a",{href:"mailto:".concat(e.mainContact.email),className:"hover:text-indigo-600 dark:hover:text-indigo-400 transition-colors",children:e.mainContact.email})]})})})]})]})})})]},e.id))]})}),(0,t.jsx)(r.A,{})]})}}},e=>{var a=a=>e(e.s=a);e.O(0,[6711,6851,9921,1028,8441,1517,7358],()=>a(2250)),_N_E=e.O()}]);