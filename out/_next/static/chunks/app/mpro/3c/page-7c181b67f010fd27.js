(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[5712],{2175:(e,a,i)=>{Promise.resolve().then(i.bind(i,2969))},2423:(e,a,i)=>{"use strict";i.d(a,{A:()=>t});let t=(0,i(7401).A)("Calendar",[["path",{d:"M8 2v4",key:"1cmpym"}],["path",{d:"M16 2v4",key:"4m81vk"}],["rect",{width:"18",height:"18",x:"3",y:"4",rx:"2",key:"1hopcy"}],["path",{d:"M3 10h18",key:"8toen8"}]])},738:(e,a,i)=>{"use strict";i.d(a,{A:()=>t});let t=(0,i(7401).A)("EyeOff",[["path",{d:"M10.733 5.076a10.744 10.744 0 0 1 11.205 6.575 1 1 0 0 1 0 .696 10.747 10.747 0 0 1-1.444 2.49",key:"ct8e1f"}],["path",{d:"M14.084 14.158a3 3 0 0 1-4.242-4.242",key:"151rxh"}],["path",{d:"M17.479 17.499a10.75 10.75 0 0 1-15.417-5.151 1 1 0 0 1 0-.696 10.75 10.75 0 0 1 4.446-5.143",key:"13bj9a"}],["path",{d:"m2 2 20 20",key:"1ooewy"}]])},2598:(e,a,i)=>{"use strict";i.d(a,{A:()=>t});let t=(0,i(7401).A)("Eye",[["path",{d:"M2.062 12.348a1 1 0 0 1 0-.696 10.75 10.75 0 0 1 19.876 0 1 1 0 0 1 0 .696 10.75 10.75 0 0 1-19.876 0",key:"1nclc0"}],["circle",{cx:"12",cy:"12",r:"3",key:"1v7zrd"}]])},4081:(e,a,i)=>{"use strict";i.d(a,{A:()=>t});let t=(0,i(7401).A)("FileText",[["path",{d:"M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z",key:"1rqfz7"}],["path",{d:"M14 2v4a2 2 0 0 0 2 2h4",key:"tnqrlb"}],["path",{d:"M10 9H8",key:"b1mrlr"}],["path",{d:"M16 13H8",key:"t4e002"}],["path",{d:"M16 17H8",key:"z1uh3a"}]])},6462:(e,a,i)=>{"use strict";i.d(a,{A:()=>t});let t=(0,i(7401).A)("Mail",[["rect",{width:"20",height:"16",x:"2",y:"4",rx:"2",key:"18n3k1"}],["path",{d:"m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7",key:"1ocrg3"}]])},2104:(e,a,i)=>{"use strict";i.d(a,{A:()=>t});let t=(0,i(7401).A)("Moon",[["path",{d:"M12 3a6 6 0 0 0 9 9 9 9 0 1 1-9-9Z",key:"a7tn18"}]])},7725:(e,a,i)=>{"use strict";i.d(a,{A:()=>t});let t=(0,i(7401).A)("Sun",[["circle",{cx:"12",cy:"12",r:"4",key:"4exip2"}],["path",{d:"M12 2v2",key:"tus03m"}],["path",{d:"M12 20v2",key:"1lh1kg"}],["path",{d:"m4.93 4.93 1.41 1.41",key:"149t6j"}],["path",{d:"m17.66 17.66 1.41 1.41",key:"ptbguv"}],["path",{d:"M2 12h2",key:"1t8f8n"}],["path",{d:"M20 12h2",key:"1q8mjw"}],["path",{d:"m6.34 17.66-1.41 1.41",key:"1m8zz5"}],["path",{d:"m19.07 4.93-1.41 1.41",key:"1shlcs"}]])},2969:(e,a,i)=>{"use strict";i.r(a),i.d(a,{default:()=>A});var t=i(5155),n=i(2115),s=i(4055),r=i(8370),o=i(5087),l=i(9219),c=i(5683),d=i(7725),h=i(2104),m=i(3467),g=i(2423),p=i(6889),u=i(4081),f=i(1902),x=i(1719),y=i(738),b=i(2598),v=i(1466),w=i(6462);let k={hidden:{opacity:0,y:30},visible:{opacity:1,y:0,transition:{duration:.8,ease:"easeOut"}}},N={hidden:{opacity:0},visible:{opacity:1,transition:{staggerChildren:.1,delayChildren:.2}}};function A(e){let{sessionTitle:a="Accelerator",sessionTime:i="11:45 AM - 1:15 PM",sessionDate:A="August 9, 2025",sessionChairperson:j="",sessionDescription:T="",papers:M=[{id:"130",title:"TYTAN: Taylor-series based Non-Linear Activation Engine for Deep Learning Accelerators",authors:["Soham Pramanik","Vimal William","Arnab Raha","Debayan Das","Amitava Mukherjee","Janet L. Paluh"],abstract:"The rapid advancement in AI architectures and the proliferation of AI-enabled systems have intensified the need for domain-specific architectures that enhance both the acceleration and energy efficiency of AI inference, particularly at the edge. This need arises from the significant resource constraints—such as computational cost and energy consumption—associated with deploying AI algorithms, which involve intensive mathematical operations across multiple layers. High-power-consuming oper- ations, including General Matrix Multiplications (GEMMs) and activation functions, can be optimized to address these challenges. Optimization strategies for AI at the edge include algorithmic approaches like quantization and pruning, as well as hardware methodologies such as domain-specific accelerators. This paper proposes TYTAN: TaYlor-series based non-linear acTivAtion eNgine, which explores the development of a General-Purpose Non-linear Approximation Engine (GPNAE). TYTAN targets the acceleration of non-linear activation functions while minimizing power consumption. The TYTAN integrates a re-configurable hardware design with a specialized algorithm that dynami- cally estimates the necessary approximation for each activation function, aimed at achieving minimal deviation from baseline accuracy. The proposed system is validated through performance evaluations with state-of-the-art AI architectures, including Con- volutional Neural Networks (CNNs) and Transformers. Results from system-level simulations using Silvaco's FreePDK45 process node demonstrate TYTAN's capability to operate at a clock frequency > 950M Hz, showcasing its effectiveness in supporting accelerated, energy-efficient AI inference at the edge, which is ∼ 2\xd7 performance improvement, with ∼ 56% power reduction and ∼ 35\xd7 lower area compared to the baseline open-source NVIDIA Deep Learning Accelerator NVDLA implementation.",mainContact:{name:"Soham Pramanik",email:"sohampramanik75@gmail.com"}},{id:"206",title:"VLSI Architecture of Hardware Accelerator for Transformer AI Model",authors:["MD NAJRUL ISLAM"],abstract:"Transformers are the heart of natural language processing(NLP) and are used for ML applications. The architecture of the transformers is made up of stacking of the encoder and decoder layers. This paper proposes a VLSI architecture of hardware accelerator for such transformer models. This architecture supports a dimensionality of 512, which has a 512\xd7512 matrix as an output for detection. In this architecture a memory module for positional encoding (POS) part consists of precomputed POS values of sine and cosine, which makes the architecture both hardware and energy efficient. For calculating the soft-max function, a simplified soft-max function is deployed in both blocks, which takes fewer LUTs, and an efficient matrix multiplication block is used to achieve a more efficient result and less computational power, reducing the area for this architecture.",mainContact:{name:"MD NAJRUL ISLAM",email:"najrulislam095@gmail.com"}},{id:"240",title:"ARIES: ADC-Less 3T1R-based nvCIM macro for Edge AI applications",authors:["Ankit Kumar Tenwar","Radheshyam Sharma","Mukul Vishnu Lokhande","Santosh Vishvakarma"],abstract:"Data-intensive applications have advanced rapidly, increasing the need for computing solutions that are both energyefficient and high-performing. This research presents a CIM (compute-in-memory) architecture without ADCs, utilizing a 3T1R bitcell inspired by the ReCAM framework and an effective voltage division method. Designed with 65nm CMOS technology, this architecture removes the requirement for high-power analogto-digital converters, leading to significant cuts in energy use and complexity. The 3T1R bitcell facilitates robust in-situ logic operations, providing stable rail-to-rail digital outputs compatible with subsequent circuit stages. Simulation results indicate a minimum latency 0.35 ns realizing an energy-efficient, low-latency and drop in energy consumption for Multiply-Accumulate (MAC) operations when contrasted with existing ADC-based systems. The design supports binary neural network (BNN) applications, offering scalability proven through a 25\xd725 macro, highlighting its suitability for edge AI systems with limited resources.",mainContact:{name:"Santosh Vishvakarma",email:"skvishvakarma@iiti.ac.in"}},{id:"291",title:"Highly scalable monolithic integration of neuron and synapse for SNN",authors:["Aravind Ananthakrishnan","Rajakumari V","Kumar Prasannajit Pradhan"],abstract:"This work presents a compact, device-level integration of neuronal and synaptic functions using two identical N-MOSFETs on a common Buried Oxide (BOX) layer. The leaky Integral-and-fire (LIF) model of a biological neuron is emulated, with one MOSFET configured as the neuron and the other as the synapse, separated by an interlayer oxide (ILO). The neuronal drain is connected to the synaptic gate, allowing synchronous operation of the integrated device. Through Sentaurus TCAD simulations, key parameters such as spike threshold, spiking frequency, and synaptic weight adaptability are validated. The spiking mechanism is governed by the Single Transistor Latch (STL) behavior, enabled by electrostatic potential buildup at the drain under negative gate bias. The synaptic device, being short-channel, exhibits current flow even at zero drain voltage, once the gate potential crosses the neuronal threshold. The impact of interface trap density on synaptic current and threshold voltage is analyzed, highlighting conductance modulation via charge trapping. Additionally, the role of ILO length is studied, revealing its inverse relationship with spike timing due to variations in the electrostatic potential gradient across the drain. The results provide a deeper understanding of the impact of scaling on co-integrated neuromorphic devices and pave the way for the development of more compact and energy-efficient neuromorphic hardware.",mainContact:{name:"Kumar Prasannajit Pradhan",email:"kppradhan@iiitdm.ac.in"}},{id:"401",title:"Design of Invertible Comparators and Max Pooling Layer using p-bits for Neural Networks",authors:["Amit Kumar Jangid","AMIT SINGH","srinivasu bodapati"],abstract:"Invertible computing presents a viable avenue for energy-efficient machine learning by facilitating low-power, probabilistic logic circuits with an invertible nature. This paper delineates the design and execution of invertible comparators and an invertible max-pooling layer utilizing probabilistic bits (p-bits) for neural networks. In contrast to conventional digital circuits, p-bit-based architectures utilize inherent stochastic behaviour to execute both forward and backward operations inside the same hardware, facilitating efficient bidirectional computations. This work offers innovative p-bit circuits that execute the comparison operation in an invertible fashion and expand these designs to develop a probabilistic max-pooling layer, an essential element in convolutional neural networks. Presented designs maintain the functional integrity of conventional forward max-pooling while facilitating invertible inference, advantageous for energy-based learning and generative models. The simulation findings indicate proper functioning, resilience to noise, and scalability of the proposed designs.",mainContact:{name:"Contact",email:"s22052@students.iitmandi.ac.in"}},{id:"415",title:"LIDER: A Tool Framework Leveraging Large Language Model (LLM) for Incremental Design Refinement",authors:["Shivam Shukla","Utkarsh Choudhary","Sneh Saurabh"],abstract:"In this paper, we propose a generalized tool framework, LIDER (LLM-based Incremental Design Engineering and Refinement), that leverages Large Language Models (LLMs) to automatically fill the verification and implementation gaps using successive refinement, reducing the manual intervention of traditional design flows significantly. We demonstrate LIDER's application in the automatic discovery of timing violations and their resolution using Google's Gemini 2.0 Flash API and the open-source timing analysis tool OpenSTA. Moreover, LIDER can produce design analysis reports, interpret timing analysis results, generate and refine timing constraints, and perform self-documentation. Hence, it can significantly reduce engineering effort while enhancing the accuracy, consistency, and speed of design closure in complex digital systems. Additionally, this work highlights the need for domain-specific fine-tuning of LLMs for more effectiveness. Therefore, a unified framework spanning across design flow tasks, such as LIDER, will facilitate the shared investment in fine-tuning and capability development, thereby promoting scalability and broader utility across the design ecosystem.",mainContact:{name:"Shivam Shukla",email:"shivam22478@iiitd.ac.in"}}]}=e,[L,I]=(0,n.useState)(!1),[C,D]=(0,n.useState)({}),[P,S]=(0,n.useState)({}),{scrollYProgress:E}=(0,o.L)();(0,n.useEffect)(()=>{window.matchMedia("(prefers-color-scheme: dark)").matches&&I(!0)},[]),(0,n.useEffect)(()=>{document.documentElement.classList.toggle("dark",L)},[L]);let z=e=>{D(a=>({...a,[e]:!a[e]}))},O=e=>{S(a=>({...a,[e]:!a[e]}))};return(0,t.jsxs)("div",{className:"relative bg-gradient-to-br from-slate-50 via-blue-50 to-indigo-50 dark:from-gray-900 dark:via-slate-900 dark:to-indigo-900 transition-colors duration-700 min-h-screen",children:[(0,t.jsx)("header",{children:(0,t.jsx)(r.default,{})}),(0,t.jsxs)("div",{className:"fixed inset-0 overflow-hidden pointer-events-none",children:[(0,t.jsx)("div",{className:"absolute -top-40 -right-40 w-80 h-80 bg-gradient-to-br from-purple-400/20 to-pink-400/20 rounded-full blur-3xl animate-pulse"}),(0,t.jsx)("div",{className:"absolute -bottom-40 -left-40 w-80 h-80 bg-gradient-to-br from-blue-400/20 to-cyan-400/20 rounded-full blur-3xl animate-pulse delay-1000"}),(0,t.jsx)("div",{className:"absolute top-1/2 left-1/2 transform -translate-x-1/2 -translate-y-1/2 w-96 h-96 bg-gradient-to-br from-indigo-400/10 to-purple-400/10 rounded-full blur-3xl animate-pulse delay-2000"})]}),(0,t.jsx)(l.P.div,{className:"fixed top-0 left-0 right-0 h-1 bg-gradient-to-r from-purple-500 via-blue-500 to-cyan-500 origin-left z-50",style:{scaleX:E}}),(0,t.jsx)(l.P.button,{whileHover:{scale:1.1},whileTap:{scale:.9},onClick:()=>I(!L),className:"fixed bottom-6 right-6 p-4 bg-white/80 dark:bg-gray-800/80 backdrop-blur-lg rounded-full shadow-2xl hover:shadow-3xl transition-all duration-300 z-40",children:L?(0,t.jsx)(d.A,{className:"w-6 h-6 text-yellow-400"}):(0,t.jsx)(h.A,{className:"w-6 h-6 text-gray-700"})}),(0,t.jsxs)("header",{className:"relative overflow-hidden mb-12",children:[(0,t.jsx)("div",{className:"absolute inset-0 bg-gradient-to-br from-purple-900/95 via-blue-900/90 to-indigo-900/95 backdrop-blur-sm"}),(0,t.jsx)("div",{className:'\n            absolute inset-0\n            bg-[url("data:image/svg+xml,%3Csvg%20width%3D%2260%22%20height%3D%2260%22%20viewBox%3D%220%200%2060%2060%22%20xmlns%3D%22http://www.w3.org/2000/svg%22%3E%3Cg%20fill%3D%22none%22%20fill-rule%3D%22evenodd%22%3E%3Cg%20fill%3D%22%23ffffff%22%20fill-opacity%3D%220.05%22%3E%3Ccircle%20cx%3D%2230%22%20cy%3D%2230%22%20r%3D%222%22/%3E%3C/g%3E%3C/g%3E%3C/svg%3E")]\n            opacity-50\n          '}),(0,t.jsxs)("div",{className:"relative z-10 px-8 py-16",children:[(0,t.jsx)(l.P.div,{initial:{scale:0,rotate:-180},animate:{scale:1,rotate:0},transition:{duration:1,ease:"easeOut"},className:"inline-block p-4 bg-white/10 backdrop-blur-lg rounded-2xl mb-6",children:(0,t.jsx)(m.A,{className:"w-12 h-12 text-white"})}),(0,t.jsx)(l.P.h1,{initial:{scale:.8,opacity:0},animate:{scale:1,opacity:1},transition:{duration:1,ease:"easeOut"},className:"text-2xl md:text-3xl lg:text-5xl font-black tracking-tight mb-4 text-white leading-tight",children:a}),(0,t.jsx)(l.P.p,{initial:{opacity:0,y:20},animate:{opacity:1,y:0},transition:{delay:.3,duration:.8},className:"text-lg text-white/90 max-w-4xl mb-8 leading-relaxed",children:T}),(0,t.jsxs)(l.P.div,{initial:{opacity:0,y:20},animate:{opacity:1,y:0},transition:{delay:.5,duration:.8},className:"flex flex-wrap gap-4 text-white/90",children:[(0,t.jsxs)("div",{className:"flex items-center gap-2 bg-white/10 backdrop-blur-lg px-4 py-2 rounded-full",children:[(0,t.jsx)(g.A,{className:"w-5 h-5"}),(0,t.jsx)("span",{children:A})]}),(0,t.jsxs)("div",{className:"flex items-center gap-2 bg-white/10 backdrop-blur-lg px-4 py-2 rounded-full",children:[(0,t.jsx)(p.A,{className:"w-5 h-5"}),(0,t.jsx)("span",{children:i})]}),(0,t.jsxs)("div",{className:"flex items-center gap-2 bg-white/10 backdrop-blur-lg px-4 py-2 rounded-full",children:[(0,t.jsx)(u.A,{className:"w-5 h-5"}),(0,t.jsxs)("span",{children:[M.length," Paper",M.length>1?"s":""]})]})]})]})]}),(0,t.jsx)("main",{className:"max-w-7xl mx-auto px-4 pb-16",children:(0,t.jsxs)(l.P.div,{variants:N,initial:"hidden",animate:"visible",className:"space-y-8",children:[(0,t.jsxs)("div",{className:"text-center mb-12",children:[(0,t.jsx)("h2",{className:"text-4xl font-bold text-gray-900 dark:text-gray-100 mb-4",children:"Research Papers"}),(0,t.jsx)("p",{className:"text-xl text-gray-600 dark:text-gray-400",children:"Explore the cutting-edge research presented in this session"})]}),M.map((e,a)=>(0,t.jsxs)(l.P.div,{variants:k,className:"bg-white/80 dark:bg-gray-800/80 backdrop-blur-lg rounded-3xl shadow-2xl border border-gray-200/50 dark:border-gray-700/50 overflow-hidden hover:shadow-3xl transition-all duration-500",children:[(0,t.jsxs)("div",{className:"bg-gradient-to-r from-indigo-600 to-purple-600 text-white p-6",children:[(0,t.jsxs)("div",{className:"flex justify-between items-start gap-4",children:[(0,t.jsxs)("div",{className:"flex-1",children:[(0,t.jsxs)("div",{className:"flex items-center gap-3 mb-3",children:[(0,t.jsx)("div",{className:"w-8 h-8 bg-white/20 rounded-full flex items-center justify-center text-sm font-bold",children:a+1}),(0,t.jsxs)("span",{className:"text-sm font-medium opacity-90",children:["Paper ID: ",e.id]})]}),(0,t.jsx)("h3",{className:"text-xl md:text-2xl font-bold leading-tight",children:e.title})]}),(0,t.jsx)(l.P.button,{whileHover:{scale:1.05},whileTap:{scale:.95},onClick:()=>z(e.id),className:"p-2 bg-white/10 backdrop-blur-lg rounded-full hover:bg-white/20 transition-all duration-300",children:C[e.id]?(0,t.jsx)(f.A,{className:"w-6 h-6"}):(0,t.jsx)(x.A,{className:"w-6 h-6"})})]}),(0,t.jsx)("div",{className:"mt-4",children:(0,t.jsx)("div",{className:"flex flex-wrap gap-2",children:e.authors.map((e,a)=>(0,t.jsx)("span",{className:"px-3 py-1 bg-white/10 backdrop-blur-lg rounded-full text-sm",children:e},a))})})]}),(0,t.jsx)(c.N,{children:C[e.id]&&(0,t.jsx)(l.P.div,{initial:{height:0,opacity:0},animate:{height:"auto",opacity:1},exit:{height:0,opacity:0},transition:{duration:.5,ease:"easeInOut"},className:"overflow-hidden",children:(0,t.jsxs)("div",{className:"p-6 space-y-6",children:[(0,t.jsxs)("div",{className:"bg-gray-50 dark:bg-gray-700/50 rounded-2xl p-6",children:[(0,t.jsxs)("div",{className:"flex items-center justify-between mb-4",children:[(0,t.jsxs)("h4",{className:"text-xl font-bold text-gray-900 dark:text-gray-100 flex items-center gap-2",children:[(0,t.jsx)(u.A,{className:"w-5 h-5"}),"Abstract"]}),(0,t.jsx)(l.P.button,{whileHover:{scale:1.05},whileTap:{scale:.95},onClick:()=>O(e.id),className:"p-2 bg-white dark:bg-gray-600 rounded-full hover:bg-gray-100 dark:hover:bg-gray-500 transition-all duration-300",children:P[e.id]?(0,t.jsx)(y.A,{className:"w-4 h-4"}):(0,t.jsx)(b.A,{className:"w-4 h-4"})})]}),(0,t.jsx)(l.P.div,{initial:!1,animate:{height:P[e.id]?"auto":"100px"},transition:{duration:.3,ease:"easeInOut"},className:"overflow-hidden",children:(0,t.jsx)("p",{className:"text-gray-700 dark:text-gray-300 leading-relaxed",children:e.abstract})})]}),(0,t.jsxs)("div",{className:"bg-gradient-to-r from-blue-50 to-indigo-50 dark:from-blue-900/20 dark:to-indigo-900/20 rounded-2xl p-6",children:[(0,t.jsxs)("h4",{className:"text-xl font-bold text-gray-900 dark:text-gray-100 mb-4 flex items-center gap-2",children:[(0,t.jsx)(v.A,{className:"w-5 h-5"}),"Main Contact"]}),(0,t.jsx)("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-4",children:(0,t.jsx)("div",{className:"space-y-2",children:(0,t.jsxs)("div",{className:"flex items-center gap-2 text-gray-700 dark:text-gray-300",children:[(0,t.jsx)(w.A,{className:"w-4 h-4 text-indigo-600"}),(0,t.jsx)("a",{href:"mailto:".concat(e.mainContact.email),className:"hover:text-indigo-600 dark:hover:text-indigo-400 transition-colors",children:e.mainContact.email})]})})})]})]})})})]},e.id))]})}),(0,t.jsx)(s.A,{})]})}}},e=>{var a=a=>e(e.s=a);e.O(0,[6711,6851,9921,1028,8441,1517,7358],()=>a(2175)),_N_E=e.O()}]);